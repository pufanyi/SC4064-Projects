@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{shoeybi2019megatron,
  title={Megatron-{LM}: Training multi-billion parameter language models using model parallelism},
  author={Shoeybi, Mohammad and Patwary, Mostofa and Puri, Raul and LeGresley, Patrick and Casper, Jared and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:1909.08053},
  year={2019}
}

@article{jia2018dissecting,
  title={Dissecting the {NVIDIA} {V}olta {GPU} architecture via microbenchmarking},
  author={Jia, Zhe and Maggioni, Marco and Staiger, Benjamin and Scarpazza, Daniele P},
  journal={arXiv preprint arXiv:1804.06826},
  year={2018}
}

@misc{cublas,
  title={{cuBLAS} Library},
  author={{NVIDIA}},
  howpublished={\url{https://developer.nvidia.com/cublas}},
  year={2024}
}

@article{williams2009roofline,
  title={Roofline: An insightful visual performance model for multicore architectures},
  author={Williams, Samuel and Waterman, Andrew and Patterson, David},
  journal={Communications of the ACM},
  volume={52},
  number={4},
  pages={65--76},
  year={2009},
  publisher={ACM}
}
